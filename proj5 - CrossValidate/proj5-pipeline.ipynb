{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "uri = \"https://gist.githubusercontent.com/guilhermesilveira/e99a526b2e7ccc6c3b70f53db43a87d2/raw/1605fc74aa778066bf2e6695e24d53cf65f2f447/machine-learning-carros-simulacao.csv\"\n",
    "\n",
    "dados = pd.read_csv(uri).drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "x = dados[['preco', 'idade_do_modelo', 'km_por_ano']]\n",
    "y = dados['vendido']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimeResult(results):\n",
    "    media = results['test_score'].mean()\n",
    "    print(\"Resultados cross validation:\",results['test_score'])\n",
    "    print(\"Média da precisão: {0:.2f}\".format(media*100),'%')\n",
    "\n",
    "    #Acurracy fica entre a média + 2(desvio_padrao) e a média - 2(desvio_padrao)\n",
    "    desvio_padrao = results['test_score'].std()\n",
    "    print(\"Desvio padrão: {0:.2f}\".format(desvio_padrao*100),'%')\n",
    "\n",
    "    acumulo_baixo = media - 2*desvio_padrao\n",
    "    acumulo_alto = media + 2*desvio_padrao\n",
    "    print(\"Acurracy esta entre: [\",acumulo_baixo*100,\"---\", acumulo_alto*100,\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Criando uma nova coluna (aleatória)</h2>\n",
    "<p>\n",
    "   A coluna representa a possibilidade de em um futuro o modelo ter que prever com dados não treinados previamente \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20    937\n",
       "19    850\n",
       "18    788\n",
       "21    685\n",
       "15    680\n",
       "16    677\n",
       "17    671\n",
       "14    619\n",
       "13    590\n",
       "12    506\n",
       "11    506\n",
       "22    487\n",
       "10    373\n",
       "9     313\n",
       "8     296\n",
       "23    256\n",
       "7     245\n",
       "6     192\n",
       "5     142\n",
       "4      93\n",
       "3      61\n",
       "2      27\n",
       "1       6\n",
       "Name: modelo_aleatorio, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "np.random.seed(SEED)\n",
    "np.random.randint(-2,2, size = 10000) #size é o numero de linhas do dataFrame\n",
    "\n",
    "dados['modelo_aleatorio'] = dados.idade_do_modelo + np.random.randint(-2,2, size = 10000)\n",
    "#Deixa o menor valor da coluna possitivo\n",
    "abss = abs(dados['modelo_aleatorio'].unique().min())\n",
    "dados['modelo_aleatorio'] = dados['modelo_aleatorio'] + abss + 1    #somando 1 para que não seja 0\n",
    "\n",
    "#Aleatoriedade adicionada e, alguns valores aparecem mais que outros -> era isso que queriamos!\n",
    "dados['modelo_aleatorio'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Pipeline</h1>\n",
    "<p>\n",
    "    O pipeline é um objeto que é responsável por executar todas as etapas do processo de previsão. <br>\n",
    "    Para utilizarmos o SVC() é necessário utilizar um StandardScaler() para normalizar os dados. <br>\n",
    "    Porém sem o pipeline, seria necessário fazer o mesmo processo para cada etapa (cada fold) do cross validation. <br>\n",
    "    Com o pipeline, é possível automatizar esse processo. <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados cross validation: [0.77042607 0.77527528 0.74887444 0.7703373  0.77158635]\n",
      "Média da precisão: 76.73 %\n",
      "Desvio padrão: 0.94 %\n",
      "Acurracy esta entre: [ 74.85280630524154 --- 78.60717067978325 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = SVC()\n",
    "\n",
    "pipeline = Pipeline([('scaler', scaler), ('model', model)])\n",
    "\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "#AO invés do modelo, aqui é passado o pipeline\n",
    "result = cross_validate(pipeline, x, y , cv=cv, groups = dados['modelo_aleatorio'])\n",
    "\n",
    "imprimeResult(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
